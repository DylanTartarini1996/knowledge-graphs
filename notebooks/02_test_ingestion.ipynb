{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "from src.config import Source, ChunkerConf, LLMConf, EmbedderConf, KnowledgeGraphConfig\n",
    "\n",
    "from src.graph.knowledge_graph import KnowledgeGraph\n",
    "\n",
    "from src.ingestion.local_ingestor import LocalIngestor\n",
    "from src.ingestion.chunker import Chunker\n",
    "from src.ingestion.cleaner import Cleaner\n",
    "from src.ingestion.embedder import ChunkEmbedder\n",
    "from src.ingestion.graph_miner import GraphMiner\n",
    "\n",
    "env = load_dotenv('config.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = Source(folder='source_folder')\n",
    "\n",
    "kg_config = KnowledgeGraphConfig(\n",
    "    uri=os.getenv(\"NEO4J_URI\"),\n",
    "    user=os.getenv(\"NEO4J_USERNAME\"),\n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    "    index_name=\"vectors\"\n",
    ")\n",
    "\n",
    "chunker_conf = ChunkerConf(\n",
    "    type=\"recursive\", \n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "llm_conf = LLMConf(\n",
    "    type=\"ollama\",\n",
    "    model=\"llama3.2:latest\", \n",
    "    temperature=0.0, \n",
    ")\n",
    "\n",
    "embedder_conf = EmbedderConf(\n",
    "    type=\"ollama\",\n",
    "    model=\"mxbai-embed-large\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Press Releases\n",
    "For demonstration purposes, here we ingest into the knowledge graph a couple of EU Commission Press Release in `.pdf` format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Documents from local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingestor = LocalIngestor(source=source)\n",
    "\n",
    "docs = ingestor.batch_ingest()\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = Cleaner()\n",
    "\n",
    "docs = cleaner.clean_documents(docs)\n",
    "\n",
    "pprint(docs[0].source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = Chunker(conf=chunker_conf)\n",
    "\n",
    "docs = chunker.chunk_documents(docs)\n",
    "\n",
    "for i in range(len(docs)):\n",
    "    print(f\"Number of chunks in doc {i}: {len(docs[i].chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = ChunkEmbedder(conf=embedder_conf)\n",
    "\n",
    "docs = embedder.embed_documents_chunks(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Nodes and Relationships from Chunk\n",
    "Here, we use the `GraphMiner` class to extract a graph of relationships and entities from each chunk of the press releases. Say we don't have any experience in this domain, so that we leave the `Ontology` class empty. \n",
    "\n",
    "Since we are using a local Llama version, it might take a while.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_miner = GraphMiner(\n",
    "    conf=llm_conf, \n",
    "    ontology=None\n",
    ")\n",
    "\n",
    "docs = graph_miner.mine_graph_from_docs(docs=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].chunks[0].nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].chunks[0].relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Graph Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_graph = KnowledgeGraph(\n",
    "    conf=kg_config, \n",
    "    embeddings_model=embedder.embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_graph._driver.verify_connectivity()\n",
    "\n",
    "knowledge_graph._driver.verify_authentication()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_graph.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_graph.index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_graph.number_of_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_graph.number_of_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_graph.number_of_relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results in Neo4j Aura\n",
    "\n",
    "Connecting to Neo4j Aura confirms visually what we already know: a Knowledge Graph made of Documents, Chunks and the entities + relationships mentioned in those Chunks has been created and it's ready to be queried either via **vector search** or via **graph search**, or even employing a **hybrid approach**.\n",
    "\n",
    "![img](../assets/graph_from_press_releases.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
