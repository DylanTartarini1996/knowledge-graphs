{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "env = load_dotenv('../config.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are revolutionizing the way we interact with language-based applications, and their importance cannot be overstated. Here are some reasons why fast language models are crucial:\n",
      "\n",
      "1. **Improved User Experience**: Fast language models enable applications to respond quickly to user input, providing a seamless and interactive experience. This is particularly important for applications like chatbots, virtual assistants, and language translation software.\n",
      "2. **Enhanced Productivity**: With fast language models, tasks like language translation, text summarization, and sentiment analysis can be performed quickly and accurately, allowing users to focus on higher-level tasks and increasing overall productivity.\n",
      "3. **Real-Time Applications**: Fast language models are essential for real-time applications like speech recognition, natural language processing, and dialogue systems. These models need to process and respond to input in a matter of milliseconds to maintain a smooth and natural conversation flow.\n",
      "4. **Competitive Advantage**: Organizations that leverage fast language models can gain a competitive advantage in the market. For instance, a company with a fast language model-based chatbot can provide 24/7 customer support, while its competitors may still be relying on human customer support agents.\n",
      "5. **Better Decision-Making**: Fast language models can process large amounts of text data quickly, providing insights and patterns that can inform business decisions. This is particularly useful in applications like sentiment analysis, where fast language models can analyze customer feedback and provide actionable insights.\n",
      "6. **Increased Accessibility**: Fast language models can help bridge the language gap by providing instant translation and interpretation services, making it easier for people who speak different languages to communicate and access information.\n",
      "7. **Support for Multimodal Interaction**: Fast language models can support multimodal interaction, such as voice, text, and gesture-based interfaces, enabling users to interact with applications in a more natural and intuitive way.\n",
      "8. **Edge Computing**: Fast language models are essential for edge computing applications, where data needs to be processed and analyzed in real-time, without relying on cloud connectivity.\n",
      "9. **Security and Surveillance**: Fast language models can be used in security and surveillance applications, such as monitoring and analyzing text-based communication channels for suspicious activity.\n",
      "10. **Research and Development**: Fast language models can accelerate research and development in areas like natural language processing, machine learning, and human-computer interaction, leading to new breakthroughs and innovations.\n",
      "\n",
      "To achieve these benefits, fast language models typically rely on:\n",
      "\n",
      "* **Model pruning**: Reducing the size and complexity of language models to improve inference speed.\n",
      "* **Quantization**: Representing model weights and activations using lower-precision data types to reduce computational requirements.\n",
      "* **Knowledge distillation**: Transferring knowledge from a large, pre-trained model to a smaller, faster model.\n",
      "* **Parallelization**: Distributing computational tasks across multiple processing units or GPUs to speed up inference.\n",
      "* **Specialized hardware**: Utilizing custom-designed hardware, such as TPUs or ASICs, to accelerate language model computations.\n",
      "\n",
      "By leveraging these techniques, fast language models can provide significant benefits and advantages in a wide range of applications, from customer service and language translation to research and development.\n"
     ]
    }
   ],
   "source": [
    "client = Groq(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"you are a helpful assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
