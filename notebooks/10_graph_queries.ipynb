{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from src.config import LLMConf, EmbedderConf, KnowledgeGraphConfig\n",
    "from src.factory.embeddings import get_embeddings\n",
    "from src.graph.knowledge_graph import KnowledgeGraph\n",
    "from neo4j import Query, Session\n",
    "from src.schema import Chunk\n",
    "env = load_dotenv('config.env')\n",
    "\n",
    "from src.utils.logger import get_logger\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_config = KnowledgeGraphConfig(\n",
    "    uri=os.getenv(\"NEO4J_URI\"),\n",
    "    user=os.getenv(\"NEO4J_USERNAME\"),\n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    "    index_name='vector'\n",
    ")\n",
    "\n",
    "embedder_conf = EmbedderConf(\n",
    "    type=os.getenv(\"EMBEDDINGS_TYPE\"),\n",
    "    model=os.getenv(\"EMBEDDINGS_MODEL_NAME\"),\n",
    ")\n",
    "\n",
    "model_conf=LLMConf(\n",
    "    type=os.getenv(\"RE_MODEL_TYPE\"),\n",
    "    model=os.getenv(\"RE_MODEL_NAME\"), \n",
    "    temperature=os.getenv(\"RE_MODEL_TEMPERATURE\"), \n",
    "    deployment=os.getenv(\"RE_MODEL_DEPLOYMENT\"),\n",
    "    api_key=os.getenv(\"RE_API_KEY\"),\n",
    "    endpoint=os.getenv(\"RE_MODEL_ENDPOINT\"),\n",
    "    api_version=os.getenv(\"RE_MODEL_API_VERSION\") or None\n",
    ")\n",
    "\n",
    "embeddings = get_embeddings(conf=embedder_conf)\n",
    "\n",
    "kg = KnowledgeGraph(conf=kg_config,embeddings_model=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = kg.get_communities()\n",
    "\n",
    "chunks_comm_1 = communities[0].chunks\n",
    "\n",
    "chunks_comm_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "\n",
    "def get_mentioned_entities(session: Session, chunk: Chunk, n_hops: int=1) -> List[Dict[str, Any]]:\n",
    "    \"\"\" \n",
    "    Follows the `MENTIONS` relationships of a given Chunk in the Graph and collects mentioned entities. \n",
    "    `n_hops` is used to indicate the number of relationship layers that could be done following entities linking.  \n",
    "    \"\"\"\n",
    "    # TODO perform n-hops retrieval\n",
    "    base_query = \"\"\"\n",
    "        MATCH (c:Chunk)\n",
    "        WHERE elementId(c) = $elementId\n",
    "        MATCH (c)-[:MENTIONS]->(mentioned)\n",
    "        RETURN collect(mentioned) AS mentioned_nodes\n",
    "    \"\"\"\n",
    "    nodes = []\n",
    "    result= session.run(base_query, elementId=chunk.chunk_id)\n",
    "    record = result.single()\n",
    "    mentioned_nodes = record[\"mentioned_nodes\"] if record else []\n",
    "    for node in mentioned_nodes:\n",
    "        nodes.append(dict(node)) \n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with kg._driver.session() as session:\n",
    "    mentioned_ents = get_mentioned_entities(session, chunk=chunks_comm_1[0])\n",
    "    \n",
    "mentioned_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def get_adjacent_chunks(session: Session, chunk: Chunk) -> Tuple[Chunk | None, Chunk | None, Chunk | None]:\n",
    "    \"\"\"\n",
    "    Returns a tuple with the previous , current and following `Chunk` \n",
    "    given an initial node characterised by a `filename` and a `chunk_id`\n",
    "    \"\"\"\n",
    "    base_query = \"\"\" \n",
    "        MATCH (current:Chunk)\n",
    "        WHERE elementId(current) = $elementId\n",
    "\n",
    "        OPTIONAL MATCH (prev:Chunk)-[:NEXT]->(current)\n",
    "        OPTIONAL MATCH (current)-[:NEXT]->(next:Chunk)\n",
    "\n",
    "        RETURN prev AS previous_chunk, current, next AS next_chunk\n",
    "    \"\"\"\n",
    "    try: \n",
    "        result = session.run(base_query, elementId=chunk.chunk_id)\n",
    "        record = result.single()\n",
    "        \n",
    "        previous_chunk = dict(record[\"previous_chunk\"]) if record[\"previous_chunk\"] else None\n",
    "        if previous_chunk:\n",
    "            previous_chunk = Chunk(\n",
    "                chunk_id=previous_chunk['chunk_id'],\n",
    "                filename=previous_chunk['filename'],\n",
    "                text=previous_chunk[\"text\"],\n",
    "            )\n",
    "            chunk.chunk_id = previous_chunk.chunk_id + 1 # original chunk id\n",
    "        next_chunk = dict(record[\"next_chunk\"]) if record[\"next_chunk\"] else None\n",
    "        if next_chunk:\n",
    "            next_chunk = Chunk(\n",
    "                chunk_id=next_chunk['chunk_id'],\n",
    "                filename=next_chunk['filename'],\n",
    "                text=next_chunk[\"text\"],\n",
    "            )\n",
    "            chunk.chunk_id = next_chunk.chunk_id-1 # original chunk id\n",
    "        \n",
    "        return previous_chunk, chunk, next_chunk\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Unable to retrieve adjacent chunks for Chunk: {chunk.chunk_id}\")\n",
    "        return None, chunk, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with kg._driver.session() as session:\n",
    "    ajacent_chunks = get_adjacent_chunks(session, chunk=chunks_comm_1[1])\n",
    "    \n",
    "ajacent_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_graph_by_communities(session: Session, community_ids: List[int], community_type: str=\"leiden\"):\n",
    "    \"\"\"\n",
    "    Creates a temporary  view of the Knowledge Graph to filter it into subgraphs given community ids.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "        MATCH (n)-[r]->(m)\n",
    "        WHERE n.community_{community_type} IN $community_values\n",
    "        RETURN n, r, m\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = session.run(query, community_values=community_ids)\n",
    "        \n",
    "        subgraph = []\n",
    "        \n",
    "        for record in result:\n",
    "            # Collecting nodes and relationships as dictionaries\n",
    "            subgraph.append({\n",
    "                \"node_1\": dict(record[\"n\"]),\n",
    "                \"relationship\": dict(record[\"r\"]),\n",
    "                \"node_2\": dict(record[\"m\"])\n",
    "            })\n",
    "        \n",
    "        return subgraph\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error while fetching subgraph: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with kg._driver.session() as session:\n",
    "    subgraph = filter_graph_by_communities(session, community_ids=[3, 4])\n",
    "    \n",
    "subgraph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
